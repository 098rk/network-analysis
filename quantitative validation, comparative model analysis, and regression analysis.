import networkx as nx
import numpy as np
import pandas as pd
from sklearn.model_selection import cross_val_score
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, f1_score, roc_auc_score
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import make_pipeline
import torch
import torch.nn.functional as F
from torch_geometric.data import Data
from torch_geometric.nn import GCNConv
import matplotlib.pyplot as plt

# Generate synthetic networks
def generate_synthetic_networks(nodes):
    er_graph = nx.erdos_renyi_graph(n=nodes, p=0.1)
    ba_graph = nx.barabasi_albert_graph(n=nodes, m=3)
    ws_graph = nx.watts_strogatz_graph(n=nodes, k=4, p=0.1)
    sbm_graph = nx.stochastic_block_model(
        [int(nodes * 0.2), int(nodes * 0.3), int(nodes * 0.5)],
        [[0.3, 0.1, 0.05], [0.1, 0.4, 0.05], [0.05, 0.05, 0.2]]
    )
    return {
        "ER": er_graph,
        "BA": ba_graph,
        "WS": ws_graph,
        "SBM": sbm_graph
    }

# Assign synthetic labels to nodes
def assign_labels(graph):
    # Assign labels based on node degree (binary classification)
    degrees = np.array([graph.degree(node) for node in graph.nodes()])
    median_degree = np.median(degrees)
    labels = (degrees > median_degree).astype(int)  # 0 or 1
    return labels

# Extract features for node classification
def extract_features(graph):
    features = {}
    for node in graph.nodes():
        features[node] = [
            graph.degree(node),
            nx.clustering(graph, node),
            nx.pagerank(graph)[node]
        ]
    return pd.DataFrame.from_dict(features, orient='index')

# Evaluate machine learning models
def evaluate_models(X, y):
    models = {
        "Random Forest": RandomForestClassifier(),
        "Logistic Regression": make_pipeline(StandardScaler(), LogisticRegression()),
    }
    results = {}
    for name, model in models.items():
        scores = cross_val_score(model, X, y, cv=5, scoring="accuracy")
        results[name] = {
            "Accuracy": np.mean(scores),
            "F1 Score": np.mean(cross_val_score(model, X, y, cv=5, scoring="f1")),
            "AUC": np.mean(cross_val_score(model, X, y, cv=5, scoring="roc_auc"))
        }
    return results

# GCN for node classification using PyTorch Geometric
class GCN(torch.nn.Module):
    def __init__(self, num_features, num_classes):
        super(GCN, self).__init__()
        self.conv1 = GCNConv(num_features, 16)
        self.conv2 = GCNConv(16, num_classes)

    def forward(self, x, edge_index):
        x = self.conv1(x, edge_index)
        x = F.relu(x)
        x = self.conv2(x, edge_index)
        return F.log_softmax(x, dim=1)

def train_gcn(graph, labels):
    edge_index = torch.tensor(list(graph.edges)).t().contiguous()
    x = torch.eye(graph.number_of_nodes())  # Use identity matrix as node features
    y = torch.tensor(labels, dtype=torch.long)

    model = GCN(num_features=x.size(1), num_classes=len(set(labels)))
    optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)

    model.train()
    for epoch in range(200):
        optimizer.zero_grad()
        out = model(x, edge_index)
        loss = F.nll_loss(out, y)
        loss.backward()
        optimizer.step()

    return model

# Compare synthetic and real-world networks
def compare_networks(synthetic_graphs):
    comparison_results = {}
    for name, graph in synthetic_graphs.items():
        comparison_results[name] = {
            "Modularity": nx.algorithms.community.modularity(graph, nx.algorithms.community.greedy_modularity_communities(graph)),
            "Clustering Coefficient": nx.average_clustering(graph),
            "Degree Distribution": np.mean([d for n, d in graph.degree()])
        }
    return comparison_results

# Main function
def main():
    node_sizes = [100, 500, 1000]
    all_results = {}

    for nodes in node_sizes:
        print(f"Analyzing networks with {nodes} nodes...")
        synthetic_graphs = generate_synthetic_networks(nodes)
        results = {}

        for name, graph in synthetic_graphs.items():
            print(f"  Graph: {name}")
            X = extract_features(graph)
            y = assign_labels(graph)  # Assign synthetic labels
            results[name] = evaluate_models(X, y)

            # Train and evaluate GCN
            gcn_model = train_gcn(graph, y)
            with torch.no_grad():
                edge_index = torch.tensor(list(graph.edges)).t().contiguous()
                x = torch.eye(graph.number_of_nodes())
                out = gcn_model(x, edge_index)
                y_pred = out.argmax(dim=1).numpy()
            results[name]["GCN"] = {
                "Accuracy": accuracy_score(y, y_pred),
                "F1 Score": f1_score(y, y_pred, average="weighted"),
                "AUC": roc_auc_score(y, out.exp()[:, 1].numpy()) if len(set(y)) == 2 else np.nan
            }

        # Compare synthetic networks
        comparison_results = compare_networks(synthetic_graphs)
        all_results[nodes] = {
            "Performance": results,
            "Properties": comparison_results
        }

    # Print results
    for nodes, results in all_results.items():
        print(f"\nResults for {nodes} nodes:")
        print("Performance:")
        print(pd.DataFrame(results["Performance"]))
        print("\nProperties:")
        print(pd.DataFrame(results["Properties"]))

if __name__ == "__main__":
    main()
